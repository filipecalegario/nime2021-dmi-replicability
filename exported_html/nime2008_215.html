
        <!doctype html>
        <html lang="en">
        <head>
            <meta charset="utf-8">
            <meta name="viewport" content="width=device-width, initial-scale=1">
            <meta name="description" content="">
            <meta name="author" content="Filipe Calegario, Mark Otto, Jacob Thornton, and Bootstrap contributors">
            <meta name="generator" content="Hugo 0.79.0">
            <title>nime2008_215 - Real Time Gesture Learning and Recognition : Towards Automatic Categorization</title>

            <link rel="canonical" href="https://getbootstrap.com/docs/5.0/examples/album/">

            <!-- Bootstrap core CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

        </head>
        <body>
            
        <header>
        <div class="navbar navbar-dark bg-dark shadow-sm">
            <div class="container">
            <a href="#" class="navbar-brand d-flex align-items-center">
                <strong>NIME 2021 - DMI Replicability - nime2008_215</strong>
            </a>
            </div>
        </div>
        </header>

        <main>

        <section class="py-3 text-left container">
            <div class="row py-lg-5">
            <div class="col-lg-12 col-md-8 mx-auto">
                <h2 class="fw-light">Real Time Gesture Learning and Recognition : Towards Automatic Categorization</h2>
                <h5 class="fw-light text-muted">Thiebaut, Jean-Baptiste and Abdallah, Samer and Robertson, Andrew and Bryan-Kinns, Nick and Plumbley, Mark D.</h5>
                <h6 class="fw-light text-muted">Length: 4 pages</h6>
                <h4 class="py-2 fw-light">Abstract</h4>
                <p class="text-muted">This research focuses on real-time gesture learning and recognition. Events arrive in a continuous stream without explicitly given boundaries. To obtain temporal accuracy, weneed to consider the lag between the detection of an eventand any effects we wish to trigger with it. Two methodsfor real time gesture recognition using a Nintendo Wii controller are presented. The first detects gestures similar to agiven template using either a Euclidean distance or a cosinesimilarity measure. The second method uses novel information theoretic methods to detect and categorize gestures inan unsupervised way. The role of supervision, detection lagand the importance of haptic feedback are discussed.</p>
                <h4 class="fw-light">Extracted URLs from PDF</h4>
                
                <div class="alert alert-danger" role="alert">
                    No URL found in the paper.
                </div>
        
           
                
                <p>
                <p>
                <a href="http://www.nime.org/proceedings/2008/nime2008_215.pdf" target="_blank" class="btn btn-primary my-2">Original PDF</a>             
                </p>
            </div>
            <iframe src="https://docs.google.com/forms/d/e/1FAIpQLSeeNTTMW8wbwNWr8AYITCU_78yFpR5Uyn0YRZG9iOcisxUCzw/viewform?embedded=true&usp=pp_url&entry.702570504=nime2008_215&entry.1715562253=Real+Time+Gesture+Learning+and+Recognition+:+Towards+Automatic+Categorization" width="700" height="600" frameborder="0" marginheight="0" marginwidth="0">Loadingâ€¦</iframe>
            </div>

         </section>

        </main>

        <footer class="text-muted py-5">
        <div class="container">
            <p class="float-end mb-1">
            <a href="#">Back to top</a>
            </p>
        </div>
        </footer>
        
        </body>
        </html>
    