
        <!doctype html>
        <html lang="en">
        <head>
            <meta charset="utf-8">
            <meta name="viewport" content="width=device-width, initial-scale=1">
            <meta name="description" content="">
            <meta name="author" content="Filipe Calegario, Mark Otto, Jacob Thornton, and Bootstrap contributors">
            <meta name="generator" content="Hugo 0.79.0">
            <title>nime2011_104 - Cognitive Architecture in Mobile Music Interactions</title>

            <link rel="canonical" href="https://getbootstrap.com/docs/5.0/examples/album/">

            <!-- Bootstrap core CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

        </head>
        <body>
            
        <header>
        <div class="navbar navbar-dark bg-dark shadow-sm">
            <div class="container">
            <a href="#" class="navbar-brand d-flex align-items-center">
                <strong>NIME 2021 - DMI Replicability - nime2011_104</strong>
            </a>
            </div>
        </div>
        </header>

        <main>

        <section class="py-3 text-left container">
            <div class="row py-lg-5">
            <div class="col-lg-12 col-md-8 mx-auto">
                <h2 class="fw-light">Cognitive Architecture in Mobile Music Interactions</h2>
                <h5 class="fw-light text-muted">Derbinsky, Nate and Essl, Georg</h5>
                <h6 class="fw-light text-muted">Length: 4 pages</h6>
                <h4 class="py-2 fw-light">Abstract</h4>
                <p class="text-muted">This paper explores how a general cognitive architecture canpragmatically facilitate the development and exploration ofinteractive music interfaces on a mobile platform. To thisend we integrated the Soar cognitive architecture into themobile music meta-environment urMus. We develop anddemonstrate four artificial agents which use diverse learningmechanisms within two mobile music interfaces. We alsoinclude details of the computational performance of theseagents, evincing that the architecture can support real-timeinteractivity on modern commodity hardware.</p>
                <h4 class="fw-light">Extracted URLs from PDF</h4>
                
                <div class="alert alert-danger" role="alert">
                    No URL found in the paper.
                </div>
        
           
                
                <p>
                <p>
                <a href="http://www.nime.org/proceedings/2011/nime2011_104.pdf" target="_blank" class="btn btn-primary my-2">Original PDF</a>             
                </p>
            </div>
            <iframe src="https://docs.google.com/forms/d/e/1FAIpQLSeeNTTMW8wbwNWr8AYITCU_78yFpR5Uyn0YRZG9iOcisxUCzw/viewform?embedded=true&usp=pp_url&entry.702570504=nime2011_104&entry.1715562253=Cognitive+Architecture+in+Mobile+Music+Interactions" width="700" height="600" frameborder="0" marginheight="0" marginwidth="0">Loadingâ€¦</iframe>
            </div>

         </section>

        </main>

        <footer class="text-muted py-5">
        <div class="container">
            <p class="float-end mb-1">
            <a href="#">Back to top</a>
            </p>
        </div>
        </footer>
        
        </body>
        </html>
    