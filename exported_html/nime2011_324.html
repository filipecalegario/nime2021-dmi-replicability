
        <!doctype html>
        <html lang="en">
        <head>
            <meta charset="utf-8">
            <meta name="viewport" content="width=device-width, initial-scale=1">
            <meta name="description" content="">
            <meta name="author" content="Filipe Calegario, Mark Otto, Jacob Thornton, and Bootstrap contributors">
            <meta name="generator" content="Hugo 0.79.0">
            <title>nime2011_324 - Creating Musical Expression using Kinect</title>

            <link rel="canonical" href="https://getbootstrap.com/docs/5.0/examples/album/">

            <!-- Bootstrap core CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

        </head>
        <body>
            
        <header>
        <div class="navbar navbar-dark bg-dark shadow-sm">
            <div class="container">
            <a href="#" class="navbar-brand d-flex align-items-center">
                <strong>NIME 2021 - DMI Replicability - nime2011_324</strong>
            </a>
            </div>
        </div>
        </header>

        <main>

        <section class="py-3 text-left container">
            <div class="row py-lg-5">
            <div class="col-lg-12 col-md-8 mx-auto">
                <h2 class="fw-light">Creating Musical Expression using Kinect</h2>
                <h5 class="fw-light text-muted">Yoo, Min-Joon and Beak, Jin-Wook and Lee, In-Kwon</h5>
                <h6 class="fw-light text-muted">Length: 2 pages</h6>
                <h4 class="py-2 fw-light">Abstract</h4>
                <p class="text-muted">Recently, Microsoft introduced a game interface called Kinect for the Xbox 360 video game platform. This interface enables users to control and interact with the game console without the need to touch a controller. It largely increases the users' degree of freedom to express their emotion. In this paper, we first describe the system we developed to use this interface for sound generation and controlling musical expression. The skeleton data are extracted from users' motions and the data are translated to pre-defined MIDI data. We then use the MIDI data to control several applications. To allow the translation between the data, we implemented a simple Kinect-to-MIDI data convertor, which is introduced in this paper. We describe two applications to make music with Kinect: we first generate sound with Max/MSP, and then control the adlib with our own adlib generating system by the body movements of the users. </p>
                <h4 class="fw-light">Extracted URLs from PDF</h4>
                <ul>
                    <li><a href="http://www.xbox.com/kinect)" target="_blank">http://www.xbox.com/kinect)</a></li>
                    <li><a href="http://en.wikipedia.org/wiki/Kinect" target="_blank">http://en.wikipedia.org/wiki/Kinect</a></li>
                    <li><a href="http://www.openni.org/)" target="_blank">http://www.openni.org/)</a></li>
                    <li><a href="http://projects.ict.usc.edu/mxr/faast/)" target="_blank">http://projects.ict.usc.edu/mxr/faast/)</a></li>
                    <li><a href="http://www.cs.unc.edu/Research/vrpn/)." target="_blank">http://www.cs.unc.edu/Research/vrpn/).</a></li>
                </ul>
           
                
        <div class="alert alert-warning" role="alert">
                <a class="alert-link" data-toggle="collapse" href="#debug" aria-expanded="false" aria-controls="debug">
                    Debug: if a extracted URL is malformed
                </a>
                        <ul class="font-monospace collapse" id="debug">

                            <li><small>http://www.xbox.com/kinect) is a new game interface for Microsoft’s Xbox 360 game console. This interface enables users to co</small></li>
                    <li><small>http://en.wikipedia.org/wiki/Kinect ).    Figure 1. Kinect consists of three components: (a) RGB camera, (b) depth sensors, and (c</small></li>
                    <li><small>http://www.openni.org/)  to connect Kinect with a PC. The PrimeSense’s NITE provided useful APIs for the manipulation of </small></li>
                    <li><small>http://projects.ict.usc.edu/mxr/faast/) to easily access the joint data extracted from the body motion. The FAAST streams the user’s ske</small></li>
                    <li><small>http://www.cs.unc.edu/Research/vrpn/).    We then implemented a Kinect-to-MIDI convertor (see Figure 2). This program listens to message</small></li>

                        </ul>
        </div>
        
                <p>
                <p>
                <a href="http://www.nime.org/proceedings/2011/nime2011_324.pdf" target="_blank" class="btn btn-primary my-2">Original PDF</a>             
                </p>
            </div>
            <iframe src="https://docs.google.com/forms/d/e/1FAIpQLSeeNTTMW8wbwNWr8AYITCU_78yFpR5Uyn0YRZG9iOcisxUCzw/viewform?embedded=true&usp=pp_url&entry.702570504=nime2011_324&entry.1715562253=Creating+Musical+Expression+using+Kinect" width="700" height="600" frameborder="0" marginheight="0" marginwidth="0">Loading…</iframe>
            </div>

         </section>

        </main>

        <footer class="text-muted py-5">
        <div class="container">
            <p class="float-end mb-1">
            <a href="#">Back to top</a>
            </p>
        </div>
        </footer>
        
        </body>
        </html>
    