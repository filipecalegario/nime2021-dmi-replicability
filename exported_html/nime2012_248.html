
        <!doctype html>
        <html lang="en">
        <head>
            <meta charset="utf-8">
            <meta name="viewport" content="width=device-width, initial-scale=1">
            <meta name="description" content="">
            <meta name="author" content="Filipe Calegario, Mark Otto, Jacob Thornton, and Bootstrap contributors">
            <meta name="generator" content="Hugo 0.79.0">
            <title>nime2012_248 - Digito: A Fine-Grain Gesturally Controlled Virtual Musical Instrument</title>

            <link rel="canonical" href="https://getbootstrap.com/docs/5.0/examples/album/">

            <!-- Bootstrap core CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

        </head>
        <body>
            
        <header>
        <div class="navbar navbar-dark bg-dark shadow-sm">
            <div class="container">
            <a href="#" class="navbar-brand d-flex align-items-center">
                <strong>NIME 2021 - DMI Replicability - nime2012_248</strong>
            </a>
            </div>
        </div>
        </header>

        <main>

        <section class="py-3 text-left container">
            <div class="row py-lg-5">
            <div class="col-lg-12 col-md-8 mx-auto">
                <h2 class="fw-light">Digito: A Fine-Grain Gesturally Controlled Virtual Musical Instrument</h2>
                <h5 class="fw-light text-muted">Nicholas Gillian and Joseph A. Paradiso</h5>
                <h6 class="fw-light text-muted">Length: 4 pages</h6>
                <h4 class="py-2 fw-light">Abstract</h4>
                <p class="text-muted">This paper presents Digito, a gesturally controlled virtual musical instrument. Digito is controlled through a number of intricate hand gestures, providing both discrete and continuous control of Digito's sound engine; with the fine-grain hand gestures captured by a 3D depth sensor and recognized using computer vision and machine learning algorithms. We describe the design and initial iterative development of Digito, the hand and finger tracking algorithms and gesture recognition algorithms that drive the system, and report the insights gained during the initial development cycles and user testing of this gesturally controlled virtual musical instrument.</p>
                <h4 class="fw-light">Extracted URLs from PDF</h4>
                <ul>
                    <li><a href="http://supercollider.sourceforge.net/" target="_blank">http://supercollider.sourceforge.net/</a></li>
                    <li><a href="http://www.openframeworks.cc/" target="_blank">http://www.openframeworks.cc/</a></li>
                    <li><a href="http://www.microsoft.com/en-us/kinectforwindows/" target="_blank">http://www.microsoft.com/en-us/kinectforwindows/</a></li>
                    <li><a href="https://github.com/ofTheo/ofxKinect" target="_blank">https://github.com/ofTheo/ofxKinect</a></li>
                    <li><a href="http://openni.org/" target="_blank">http://openni.org/</a></li>
                </ul>
           
                
        <div class="alert alert-warning" role="alert">
                <a class="alert-link" data-toggle="collapse" href="#debug" aria-expanded="false" aria-controls="debug">
                    Debug: if a extracted URL is malformed
                </a>
                        <ul class="font-monospace collapse" id="debug">

                            <li><small>http://supercollider.sourceforge.net/Figure 1: (a) Digito’s main visual feedback illustrating the continuous gesture feedback and 12 not</small></li>
                    <li><small>http://www.openframeworks.cc/exists.This 3D virtual space contains six layers (repre-senting octaves) each containing twelve t</small></li>
                    <li><small>http://www.microsoft.com/en-us/kinectforwindows/6https://github.com/ofTheo/ofxKinect7http://openni.org/30 frames per second. An initial two-fold </small></li>
                    <li><small>https://github.com/ofTheo/ofxKinect7http://openni.org/30 frames per second. An initial two-fold depth threshold-ing operation is per</small></li>
                    <li><small>http://openni.org/30 frames per second. An initial two-fold depth threshold-ing operation is performed on the raw de</small></li>

                        </ul>
        </div>
        
                <p>
                <p>
                <a href="http://www.nime.org/proceedings/2012/nime2012_248.pdf" target="_blank" class="btn btn-primary my-2">Original PDF</a>             
                </p>
            </div>
            <iframe src="https://docs.google.com/forms/d/e/1FAIpQLSeeNTTMW8wbwNWr8AYITCU_78yFpR5Uyn0YRZG9iOcisxUCzw/viewform?embedded=true&usp=pp_url&entry.702570504=nime2012_248&entry.1715562253=Digito:+A+Fine-Grain+Gesturally+Controlled+Virtual+Musical+Instrument" width="700" height="600" frameborder="0" marginheight="0" marginwidth="0">Loading…</iframe>
            </div>

         </section>

        </main>

        <footer class="text-muted py-5">
        <div class="container">
            <p class="float-end mb-1">
            <a href="#">Back to top</a>
            </p>
        </div>
        </footer>
        
        </body>
        </html>
    