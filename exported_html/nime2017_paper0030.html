
        <!doctype html>
        <html lang="en">
        <head>
            <meta charset="utf-8">
            <meta name="viewport" content="width=device-width, initial-scale=1">
            <meta name="description" content="">
            <meta name="author" content="Filipe Calegario, Mark Otto, Jacob Thornton, and Bootstrap contributors">
            <meta name="generator" content="Hugo 0.79.0">
            <title>nime2017_paper0030 - Exploring Pitch and Timbre through 3D Spaces: Embodied Models in Virtual Reality as a Basis for Performance Systems Design</title>

            <link rel="canonical" href="https://getbootstrap.com/docs/5.0/examples/album/">

            <!-- Bootstrap core CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

        </head>
        <body>
            
        <header>
        <div class="navbar navbar-dark bg-dark shadow-sm">
            <div class="container">
            <a href="#" class="navbar-brand d-flex align-items-center">
                <strong>NIME 2021 - DMI Replicability - nime2017_paper0030</strong>
            </a>
            </div>
        </div>
        </header>

        <main>

        <section class="py-3 text-left container">
            <div class="row py-lg-5">
            <div class="col-lg-12 col-md-8 mx-auto">
                <h2 class="fw-light">Exploring Pitch and Timbre through 3D Spaces: Embodied Models in Virtual Reality as a Basis for Performance Systems Design</h2>
                <h5 class="fw-light text-muted">Richard Graham and Brian Bridges and Christopher Manzione and William Brent</h5>
                <h6 class="fw-light text-muted">Length: 6 pages</h6>
                <h4 class="py-2 fw-light">Abstract</h4>
                <p class="text-muted">Our paper builds on an ongoing collaboration between theorists and practitioners within the computer music community, with a specific focus on three-dimensional environments as an incubator for performance systems design. In particular, we are concerned with how to provide accessible means of controlling spatialization and timbral shaping in an integrated manner through the collection of performance data from various modalities from an electric guitar with a multichannel audio output. This paper will focus specifically on the combination of pitch data treated within tonal models and the detection of physical performance gestures using timbral feature extraction algorithms. We discuss how these tracked gestures may be connected to concepts and dynamic relationships from embodied cognition, expanding on performative models for pitch and timbre spaces. Finally, we explore how these ideas support connections between sonic, formal and performative dimensions. This includes instrumental technique detection scenes and mapping strategies aimed at bridging music performance gestures across physical and conceptual planes. </p>
                <h4 class="fw-light">Extracted URLs from PDF</h4>
                <ul>
                    <li><a href="http://bit.ly/2kP9sce" target="_blank">http://bit.ly/2kP9sce</a></li>
                    <li><a href="http://bit.ly/2pwQntW" target="_blank">http://bit.ly/2pwQntW</a></li>
                    <li><a href="http://bit.ly/2kSdfBK" target="_blank">http://bit.ly/2kSdfBK</a></li>
                    <li><a href="http://bit.ly/2kNWPv8" target="_blank">http://bit.ly/2kNWPv8</a></li>
                    <li><a href="https://vimeo.com/202093804" target="_blank">https://vimeo.com/202093804</a></li>
                    <li><a href="https://vimeo.com/202093804" target="_blank">https://vimeo.com/202093804</a></li>
                    <li><a href="http://williambrent.conflations.com" target="_blank">http://williambrent.conflations.com</a></li>
                    <li><a href="http://www.fftw.org" target="_blank">http://www.fftw.org</a></li>
                    <li><a href="http://www.katjaas.nl/helmholtz/helmholtz.html" target="_blank">http://www.katjaas.nl/helmholtz/helmholtz.html</a></li>
                </ul>
           
                
        <div class="alert alert-warning" role="alert">
                <a class="alert-link" data-toggle="collapse" href="#debug" aria-expanded="false" aria-controls="debug">
                    Debug: if a extracted URL is malformed
                </a>
                        <ul class="font-monospace collapse" id="debug">

                            <li><small>http://bit.ly/2kP9sce  quite flat to ensure a clean note attack. A rudimentary classification example is given2, where </small></li>
                    <li><small>http://bit.ly/2pwQntW  3 waveSlope~ example video 2: http://bit.ly/2kSdfBK  158 Table 1. Finger Picked v. Picked Note</small></li>
                    <li><small>http://bit.ly/2kSdfBK  158 Table 1. Finger Picked v. Picked Note Events Finger Picked v. Picked Note Events - setting</small></li>
                    <li><small>http://bit.ly/2kNWPv8  Figure 2. Different attack-projection-linearity profiles from Graham and Bridges (2015) [6]  In</small></li>
                    <li><small>https://vimeo.com/202093804  7 Disrupt/Construct: https://vimeo.com/202093804  gesture data is recorded from an augmented ins</small></li>
                    <li><small>https://vimeo.com/202093804  gesture data is recorded from an augmented instrument and mapped to determine a variety of inter</small></li>
                    <li><small>http://williambrent.conflations.com>. Accessed January 2017. [2] B. Bridges and R. Graham, Electroacoustic Music as Embodied Cogniti</small></li>
                    <li><small>http://www.fftw.org> Accessed January 2017. [4] R. Graham. Expansion of Electronic Guitar Performance Practice throug</small></li>
                    <li><small>http://www.katjaas.nl/helmholtz/helmholtz.html>. Accessed January 2017. 162</small></li>

                        </ul>
        </div>
        
                <p>
                <p>
                <a href="http://www.nime.org/proceedings/2017/nime2017_paper0030.pdf" target="_blank" class="btn btn-primary my-2">Original PDF</a>             
                </p>
            </div>
            <iframe src="https://docs.google.com/forms/d/e/1FAIpQLSeeNTTMW8wbwNWr8AYITCU_78yFpR5Uyn0YRZG9iOcisxUCzw/viewform?embedded=true&usp=pp_url&entry.702570504=nime2017_paper0030&entry.1715562253=Exploring+Pitch+and+Timbre+through+3D+Spaces:+Embodied+Models+in+Virtual+Reality+as+a+Basis+for+Performance+Systems+Design" width="700" height="600" frameborder="0" marginheight="0" marginwidth="0">Loadingâ€¦</iframe>
            </div>

         </section>

        </main>

        <footer class="text-muted py-5">
        <div class="container">
            <p class="float-end mb-1">
            <a href="#">Back to top</a>
            </p>
        </div>
        </footer>
        
        </body>
        </html>
    