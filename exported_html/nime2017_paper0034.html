
        <!doctype html>
        <html lang="en">
        <head>
            <meta charset="utf-8">
            <meta name="viewport" content="width=device-width, initial-scale=1">
            <meta name="description" content="">
            <meta name="author" content="Filipe Calegario, Mark Otto, Jacob Thornton, and Bootstrap contributors">
            <meta name="generator" content="Hugo 0.79.0">
            <title>nime2017_paper0034 - Revgest: Augmenting Gestural Musical Instruments with Revealed Virtual Objects</title>

            <link rel="canonical" href="https://getbootstrap.com/docs/5.0/examples/album/">

            <!-- Bootstrap core CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

        </head>
        <body>
            
        <header>
        <div class="navbar navbar-dark bg-dark shadow-sm">
            <div class="container">
            <a href="#" class="navbar-brand d-flex align-items-center">
                <strong>NIME 2021 - DMI Replicability - nime2017_paper0034</strong>
            </a>
            </div>
        </div>
        </header>

        <main>

        <section class="py-3 text-left container">
            <div class="row py-lg-5">
            <div class="col-lg-12 col-md-8 mx-auto">
                <h2 class="fw-light">Revgest: Augmenting Gestural Musical Instruments with Revealed Virtual Objects</h2>
                <h5 class="fw-light text-muted">Florent Berthaut and Cagan Arslan and Laurent Grisoni</h5>
                <h6 class="fw-light text-muted">Length: 6 pages</h6>
                <h4 class="py-2 fw-light">Abstract</h4>
                <p class="text-muted">Gestural interfaces, which make use of physiological signals, hand / body postures or movements, have become widespread for musical expression.  While they may increase the transparency and expressiveness of instruments, they may also result in limited agency, for musicians as well as for spectators. This problem becomes especially true when the implemented mappings between gesture and music are subtle or complex. These instruments may also restrict the appropriation possibilities of controls, by comparison to physical interfaces.  Most existing solutions to these issues are based on distant and/or limited visual feedback (LEDs, small screens).  Our approach is to augment the gestures themselves with revealed virtual objects.  Our contributions are, first a novel approach of visual feedback that allow for additional expressiveness, second a software pipeline for pixel-level feedback and control that ensures tight coupling between sound and visuals, and third, a design space for extending gestural control using revealed interfaces. We also demonstrate and evaluate our approach with the augmentation of three existing gestural musical instruments.</p>
                <h4 class="fw-light">Extracted URLs from PDF</h4>
                <ul>
                    <li><a href="http://forge.lifl.fr/Revil." target="_blank">http://forge.lifl.fr/Revil.</a></li>
                    <li><a href="https://
www.khronos.org/opengl/wiki/Image_Load_Store" target="_blank">https://
www.khronos.org/opengl/wiki/Image_Load_Store</a></li>
                    <li><a href="http://mimugloves.com" target="_blank">http://mimugloves.com</a></li>
                </ul>
           
                
        <div class="alert alert-warning" role="alert">
                <a class="alert-link" data-toggle="collapse" href="#debug" aria-expanded="false" aria-controls="debug">
                    Debug: if a extracted URL is malformed
                </a>
                        <ul class="font-monospace collapse" id="debug">

                            <li><small>http://forge.lifl.fr/Revil.2.2.1Sensing the physical spaceIn order to display the virtual objects, our pipeline firstneeds </small></li>
                    <li><small>https://www.khronos.org/opengl/wiki/Image_Load_Store,2017. [Online; accessed 30-December-2016].[13] J. Malloch and M. M. Wanderley. The t-stick: From</small></li>
                    <li><small>http://mimugloves.com, 2017.[Online; accessed 30-December-2016].[16] T. Mitchell and I. Heap. Soundgrasp: A gesturalin</small></li>

                        </ul>
        </div>
        
                <p>
                <p>
                <a href="http://www.nime.org/proceedings/2017/nime2017_paper0034.pdf" target="_blank" class="btn btn-primary my-2">Original PDF</a>             
                </p>
            </div>
            <iframe src="https://docs.google.com/forms/d/e/1FAIpQLSeeNTTMW8wbwNWr8AYITCU_78yFpR5Uyn0YRZG9iOcisxUCzw/viewform?embedded=true&usp=pp_url&entry.702570504=nime2017_paper0034&entry.1715562253=Revgest:+Augmenting+Gestural+Musical+Instruments+with+Revealed+Virtual+Objects" width="700" height="600" frameborder="0" marginheight="0" marginwidth="0">Loadingâ€¦</iframe>
            </div>

         </section>

        </main>

        <footer class="text-muted py-5">
        <div class="container">
            <p class="float-end mb-1">
            <a href="#">Back to top</a>
            </p>
        </div>
        </footer>
        
        </body>
        </html>
    