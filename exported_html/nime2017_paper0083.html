
        <!doctype html>
        <html lang="en">
        <head>
            <meta charset="utf-8">
            <meta name="viewport" content="width=device-width, initial-scale=1">
            <meta name="description" content="">
            <meta name="author" content="Filipe Calegario, Mark Otto, Jacob Thornton, and Bootstrap contributors">
            <meta name="generator" content="Hugo 0.79.0">
            <title>nime2017_paper0083 - Exploring the Myo controller for sonic microinteraction</title>

            <link rel="canonical" href="https://getbootstrap.com/docs/5.0/examples/album/">

            <!-- Bootstrap core CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

        </head>
        <body>
            
        <header>
        <div class="navbar navbar-dark bg-dark shadow-sm">
            <div class="container">
            <a href="#" class="navbar-brand d-flex align-items-center">
                <strong>NIME 2021 - DMI Replicability - nime2017_paper0083</strong>
            </a>
            </div>
        </div>
        </header>

        <main>

        <section class="py-3 text-left container">
            <div class="row py-lg-5">
            <div class="col-lg-12 col-md-8 mx-auto">
                <h2 class="fw-light">Exploring the Myo controller for sonic microinteraction</h2>
                <h5 class="fw-light text-muted">Alexander Refsum Jensenius and Victor Gonzalez Sanchez and Agata Zelechowska and Kari Anne Vadstensvik Bjerkestrand</h5>
                <h6 class="fw-light text-muted">Length: 4 pages</h6>
                <h4 class="py-2 fw-light">Abstract</h4>
                <p class="text-muted">This paper explores sonic microinteraction using muscle sensing through the Myo armband. The first part presents results from a small series of experiments aimed at finding the baseline micromotion and muscle activation data of people being at rest or performing short/small actions. The second part presents the prototype instrument MicroMyo, built around the concept of making sound with little motion. The instrument plays with the convention that inputting more energy into an instrument results in more sound. MicroMyo, on the other hand, is built so that the less you move, the more it sounds. Our user study shows that while such an "inverse instrument" may seem puzzling at first, it also opens a space for interesting musical interactions. </p>
                <h4 class="fw-light">Extracted URLs from PDF</h4>
                <ul>
                    <li><a href="https://www.myo.com/" target="_blank">https://www.myo.com/</a></li>
                    <li><a href="https://github.com/vicgos/Micromotion1/" target="_blank">https://github.com/vicgos/Micromotion1/</a></li>
                    <li><a href="https://github.com/alexarje/MicroMyo/" target="_blank">https://github.com/alexarje/MicroMyo/</a></li>
                    <li><a href="https://github.com/JulesFrancoise/myo-for-max/" target="_blank">https://github.com/JulesFrancoise/myo-for-max/</a></li>
                </ul>
           
                
        <div class="alert alert-warning" role="alert">
                <a class="alert-link" data-toggle="collapse" href="#debug" aria-expanded="false" aria-controls="debug">
                    Debug: if a extracted URL is malformed
                </a>
                        <ul class="font-monospace collapse" id="debug">

                            <li><small>https://www.myo.com/4422.1Retrieving DataRaw EMG and accelerometer data from multiple Myo arm-bands was acquired th</small></li>
                    <li><small>https://github.com/vicgos/Micromotion1/Figure 3: Placement of the Myo for Experiment 2.The experiment consisted of two main scenarios: (1</small></li>
                    <li><small>https://github.com/alexarje/MicroMyo/4https://github.com/JulesFrancoise/myo-for-max/444Table 3: Mappings from action to soundSound ef</small></li>
                    <li><small>https://github.com/JulesFrancoise/myo-for-max/444Table 3: Mappings from action to soundSound effectMotion/forceSensorTimbreMuscle tensionE</small></li>

                        </ul>
        </div>
        
                <p>
                <p>
                <a href="http://www.nime.org/proceedings/2017/nime2017_paper0083.pdf" target="_blank" class="btn btn-primary my-2">Original PDF</a>             
                </p>
            </div>
            <iframe src="https://docs.google.com/forms/d/e/1FAIpQLSeeNTTMW8wbwNWr8AYITCU_78yFpR5Uyn0YRZG9iOcisxUCzw/viewform?embedded=true&usp=pp_url&entry.702570504=nime2017_paper0083&entry.1715562253=Exploring+the+Myo+controller+for+sonic+microinteraction" width="700" height="600" frameborder="0" marginheight="0" marginwidth="0">Loadingâ€¦</iframe>
            </div>

         </section>

        </main>

        <footer class="text-muted py-5">
        <div class="container">
            <p class="float-end mb-1">
            <a href="#">Back to top</a>
            </p>
        </div>
        </footer>
        
        </body>
        </html>
    