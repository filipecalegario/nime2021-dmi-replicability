
        <!doctype html>
        <html lang="en">
        <head>
            <meta charset="utf-8">
            <meta name="viewport" content="width=device-width, initial-scale=1">
            <meta name="description" content="">
            <meta name="author" content="Filipe Calegario, Mark Otto, Jacob Thornton, and Bootstrap contributors">
            <meta name="generator" content="Hugo 0.79.0">
            <title>nime2019_paper051 - Expressive potentials of motion capture in musical performance</title>

            <link rel="canonical" href="https://getbootstrap.com/docs/5.0/examples/album/">

            <!-- Bootstrap core CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

        </head>
        <body>
            
        <header>
        <div class="navbar navbar-dark bg-dark shadow-sm">
            <div class="container">
            <a href="#" class="navbar-brand d-flex align-items-center">
                <strong>NIME 2021 - DMI Replicability - nime2019_paper051</strong>
            </a>
            </div>
        </div>
        </header>

        <main>

        <section class="py-3 text-left container">
            <div class="row py-lg-5">
            <div class="col-lg-12 col-md-8 mx-auto">
                <h2 class="fw-light">Expressive potentials of motion capture in musical performance</h2>
                <h5 class="fw-light text-muted">Nicolas Bazoge and Ronan Gaugne and Florian Nouviale and Valérie Gouranton and Bruno Bossis</h5>
                <h6 class="fw-light text-muted">Length: 6 pages</h6>
                <h4 class="py-2 fw-light">Abstract</h4>
                <p class="text-muted">The paper presents the electronic music performance project Vis Insita implementing the design of experimental instrumental interfaces based on optical motion capture technology with passive infrared markers (MoCap), and the analysis of their use in a real scenic presentation context. Because of MoCap's predisposition to capture the movements of the body, a lot of research and musical applications in the performing arts concern dance or the sonification of gesture. For our research, we wanted to move away from the capture of the human body to analyse the possibilities of a kinetic object handled by a performer, both in terms of musical expression, but also in the broader context of a multimodal scenic interpretation.</p>
                <h4 class="fw-light">Extracted URLs from PDF</h4>
                <ul>
                    <li><a href="https://vimeo.com/328923793" target="_blank">https://vimeo.com/328923793</a></li>
                    <li><a href="https://journees-arts-culture-sup.fr/" target="_blank">https://journees-arts-culture-sup.fr/</a></li>
                    <li><a href="https://jsm.irisa.fr/" target="_blank">https://jsm.irisa.fr/</a></li>
                    <li><a href="https://github.com/vrpn/vrpn/wiki" target="_blank">https://github.com/vrpn/vrpn/wiki</a></li>
                    <li><a href="https://cycling74.com/" target="_blank">https://cycling74.com/</a></li>
                </ul>
           
                
        <div class="alert alert-warning" role="alert">
                <a class="alert-link" data-toggle="collapse" href="#debug" aria-expanded="false" aria-controls="debug">
                    Debug: if a extracted URL is malformed
                </a>
                        <ul class="font-monospace collapse" id="debug">

                            <li><small>https://vimeo.com/3289237932662.METHODOLOGYThe project was carried out in two stages at the Universityof Rennes: (1) a res</small></li>
                    <li><small>https://journees-arts-culture-sup.fr/3https://jsm.irisa.fr/4from the German manufacturer A.R. Trackingobject that could be handed in s</small></li>
                    <li><small>https://jsm.irisa.fr/4from the German manufacturer A.R. Trackingobject that could be handed in several ways and capable</small></li>
                    <li><small>https://github.com/vrpn/vrpn/wiki[rx][ry][rz]. The OSC data from ARTtoOSC is then sentto µZYX via UDP in order to speed up the comm</small></li>
                    <li><small>https://cycling74.com/268people per performance, for one hundred and twenty peopleout of the four performances given.T</small></li>

                        </ul>
        </div>
        
                <p>
                <p>
                <a href="http://www.nime.org/proceedings/2019/nime2019_paper051.pdf" target="_blank" class="btn btn-primary my-2">Original PDF</a>             
                </p>
            </div>
            <iframe src="https://docs.google.com/forms/d/e/1FAIpQLSeeNTTMW8wbwNWr8AYITCU_78yFpR5Uyn0YRZG9iOcisxUCzw/viewform?usp=pp_url&entry.702570504=nime2019_paper051&entry.1715562253=Expressive+potentials+of+motion+capture+in+musical+performance" width="700" height="600" frameborder="0" marginheight="0" marginwidth="0">Loading…</iframe>
            </div>

            
            
         </section>
        

        </main>

        <footer class="text-muted py-5">
        <div class="container">
            <p class="float-end mb-1">
            <a href="#">Back to top</a>
            </p>
        </div>
        </footer>
        
        </body>
        </html>
    