
        <!doctype html>
        <html lang="en">
        <head>
            <meta charset="utf-8">
            <meta name="viewport" content="width=device-width, initial-scale=1">
            <meta name="description" content="">
            <meta name="author" content="Filipe Calegario, Mark Otto, Jacob Thornton, and Bootstrap contributors">
            <meta name="generator" content="Hugo 0.79.0">
            <title>nime2019_paper060 - Adaptive Mapping of Sound Collections for Data-driven Musical Interfaces</title>

            <link rel="canonical" href="https://getbootstrap.com/docs/5.0/examples/album/">

            <!-- Bootstrap core CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

        </head>
        <body>
            
        <header>
        <div class="navbar navbar-dark bg-dark shadow-sm">
            <div class="container">
            <a href="#" class="navbar-brand d-flex align-items-center">
                <strong>NIME 2021 - DMI Replicability - nime2019_paper060</strong>
            </a>
            </div>
        </div>
        </header>

        <main>

        <section class="py-3 text-left container">
            <div class="row py-lg-5">
            <div class="col-lg-12 col-md-8 mx-auto">
                <h2 class="fw-light">Adaptive Mapping of Sound Collections for Data-driven Musical Interfaces</h2>
                <h5 class="fw-light text-muted">Gerard Roma and Owen Green and Pierre Alexandre Tremblay</h5>
                <h6 class="fw-light text-muted">Length: 6 pages</h6>
                <h4 class="py-2 fw-light">Abstract</h4>
                <p class="text-muted">Descriptor spaces have become an ubiquitous interaction paradigm for music based on collections of audio samples. However, most systems rely on a small predefined set of descriptors, which the user is often required to understand and choose from. There is no guarantee that the chosen descriptors are relevant for a given collection. In addition, this method does not scale to longer samples that require higher-dimensional descriptions, which biases systems towards the use of short samples. In this paper we propose novel framework for automatic creation of interactive sound spaces from sound collections using feature learning and dimensionality reduction. The framework is implemented as a software library using the SuperCollider language. We compare several algorithms and describe some example interfaces for interacting with the resulting spaces. Our experiments signal the potential of unsupervised algorithms for creating data-driven musical interfaces.</p>
                <h4 class="fw-light">Extracted URLs from PDF</h4>
                <ul>
                    <li><a href="http://forumnet.ircam.fr/product/orchids-en/" target="_blank">http://forumnet.ircam.fr/product/orchids-en/</a></li>
                    <li><a href="https://scikit-learn.org/" target="_blank">https://scikit-learn.org/</a></li>
                    <li><a href="https://github.com/JustGlowing/minisom" target="_blank">https://github.com/JustGlowing/minisom</a></li>
                    <li><a href="https://networkx.github.io/" target="_blank">https://networkx.github.io/</a></li>
                    <li><a href="http://flucoma.org/NIME-2019/" target="_blank">http://flucoma.org/NIME-2019/</a></li>
                    <li><a href="https://github.com/crucialfelix/supercolliderjs" target="_blank">https://github.com/crucialfelix/supercolliderjs</a></li>
                    <li><a href="https://github.com/flucoma/FluidCorpusMap." target="_blank">https://github.com/flucoma/FluidCorpusMap.</a></li>
                </ul>
           
                
        <div class="alert alert-warning" role="alert">
                <a class="alert-link" data-toggle="collapse" href="#debug" aria-expanded="false" aria-controls="debug">
                    Debug: if a extracted URL is malformed
                </a>
                        <ul class="font-monospace collapse" id="debug">

                            <li><small>http://forumnet.ircam.fr/product/orchids-en/2https://scikit-learn.org/3https://github.com/JustGlowing/minisom4https://networkx.github.io/5ht</small></li>
                    <li><small>https://scikit-learn.org/3https://github.com/JustGlowing/minisom4https://networkx.github.io/5http://flucoma.org/NIME-2019/</small></li>
                    <li><small>https://github.com/JustGlowing/minisom4https://networkx.github.io/5http://flucoma.org/NIME-2019/Figure 2: Visualization of each dataset</small></li>
                    <li><small>https://networkx.github.io/5http://flucoma.org/NIME-2019/Figure 2: Visualization of each dataset (top: drums,middle: SOL, bo</small></li>
                    <li><small>http://flucoma.org/NIME-2019/Figure 2: Visualization of each dataset (top: drums,middle: SOL, bottom: urban) using MFCC feature</small></li>
                    <li><small>https://github.com/crucialfelix/supercolliderjs316Figure 3: Visualization of each dataset (top: drums,middle:SOL, bottom:urban) using autoenco</small></li>
                    <li><small>https://github.com/flucoma/FluidCorpusMap.We nowdescribe three example instruments that show its potentialfor creating data-driven musical </small></li>

                        </ul>
        </div>
        
                <p>
                <p>
                <a href="http://www.nime.org/proceedings/2019/nime2019_paper060.pdf" target="_blank" class="btn btn-primary my-2">Original PDF</a>             
                </p>
            </div>
            <iframe src="https://docs.google.com/forms/d/e/1FAIpQLSeeNTTMW8wbwNWr8AYITCU_78yFpR5Uyn0YRZG9iOcisxUCzw/viewform?embedded=true&usp=pp_url&entry.702570504=nime2019_paper060&entry.1715562253=Adaptive+Mapping+of+Sound+Collections+for+Data-driven+Musical+Interfaces" width="700" height="600" frameborder="0" marginheight="0" marginwidth="0">Loadingâ€¦</iframe>
            </div>

         </section>

        </main>

        <footer class="text-muted py-5">
        <div class="container">
            <p class="float-end mb-1">
            <a href="#">Back to top</a>
            </p>
        </div>
        </footer>
        
        </body>
        </html>
    