
        <!doctype html>
        <html lang="en">
        <head>
            <meta charset="utf-8">
            <meta name="viewport" content="width=device-width, initial-scale=1">
            <meta name="description" content="">
            <meta name="author" content="Filipe Calegario, Mark Otto, Jacob Thornton, and Bootstrap contributors">
            <meta name="generator" content="Hugo 0.79.0">
            <title>nime2020_paper58 - ExSampling: a system for the real-time ensemble performance of field-recorded environmental sounds</title>

            <link rel="canonical" href="https://getbootstrap.com/docs/5.0/examples/album/">

            <!-- Bootstrap core CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

        </head>
        <body>
            
        <header>
        <div class="navbar navbar-dark bg-dark shadow-sm">
            <div class="container">
            <a href="#" class="navbar-brand d-flex align-items-center">
                <strong>NIME 2021 - DMI Replicability - nime2020_paper58</strong>
            </a>
            </div>
        </div>
        </header>

        <main>

        <section class="py-3 text-left container">
            <div class="row py-lg-5">
            <div class="col-lg-12 col-md-8 mx-auto">
                <h2 class="fw-light">ExSampling: a system for the real-time ensemble performance of field-recorded environmental sounds</h2>
                <h5 class="fw-light text-muted">Kobayashi, Atsuya and Anzai, Reo and Tokui, Nao</h5>
                <h6 class="fw-light text-muted">Length: 4 pages</h6>
                <h4 class="py-2 fw-light">Abstract</h4>
                <p class="text-muted">We propose ExSampling: an integrated system of recording application and Deep Learning environment for a real-time music performance of environmental sounds sampled by field recording. Automated sound mapping to Ableton Live tracks by Deep Learning enables field recording to be applied to real-time performance, and create interactions among sound recorder, composers and performers.</p>
                <h4 class="fw-light">Extracted URLs from PDF</h4>
                <ul>
                    <li><a href="https://www.ableton.com/en/live/" target="_blank">https://www.ableton.com/en/live/</a></li>
                    <li><a href="http://opensoundcontrol.org/" target="_blank">http://opensoundcontrol.org/</a></li>
                    <li><a href="https://github.com/mattdiamond/Recorderjs" target="_blank">https://github.com/mattdiamond/Recorderjs</a></li>
                    <li><a href="https://www.w3.org/TR/webaudio/" target="_blank">https://www.w3.org/TR/webaudio/</a></li>
                    <li><a href="https://ngrok.com/" target="_blank">https://ngrok.com/</a></li>
                    <li><a href="https://www.python.org/" target="_blank">https://www.python.org/</a></li>
                    <li><a href="https://cycling74.com/" target="_blank">https://cycling74.com/</a></li>
                    <li><a href="https://www.ableton.com/en/live/max-for-live/" target="_blank">https://www.ableton.com/en/live/max-for-live/</a></li>
                    <li><a href="https://p5js.org/" target="_blank">https://p5js.org/</a></li>
                    <li><a href="https://www.w3.org/TR/geolocation-API/" target="_blank">https://www.w3.org/TR/geolocation-API/</a></li>
                    <li><a href="https://docs.mapbox.com/api/" target="_blank">https://docs.mapbox.com/api/</a></li>
                    <li><a href="https://librosa.github.io/librosa/" target="_blank">https://librosa.github.io/librosa/</a></li>
                    <li><a href="https://www.kaggle.com/" target="_blank">https://www.kaggle.com/</a></li>
                    <li><a href="https://www.tensorflow.org/" target="_blank">https://www.tensorflow.org/</a></li>
                    <li><a href="https://cclab.sfc.keio.ac.jp/paper/exsampling/." target="_blank">https://cclab.sfc.keio.ac.jp/paper/exsampling/.</a></li>
                    <li><a href="https://github.com/daisukelab/ml-sound-classifier" target="_blank">https://github.com/daisukelab/ml-sound-classifier</a></li>
                </ul>
           
                
        <div class="alert alert-warning" role="alert">
                <a class="alert-link" data-toggle="collapse" href="#debug" aria-expanded="false" aria-controls="debug">
                    Debug: if a extracted URL is malformed
                </a>
                        <ul class="font-monospace collapse" id="debug">

                            <li><small>https://www.ableton.com/en/live/ Even though sounds are constantly generated throughout the        world, the time spends </small></li>
                    <li><small>http://opensoundcontrol.org/ 3 https://github.com/mattdiamond/Recorderjs 4 https://www.w3.org/TR/webaudio/  Proceedings of t</small></li>
                    <li><small>https://github.com/mattdiamond/Recorderjs 4 https://www.w3.org/TR/webaudio/  Proceedings of the International Conference on New Interfaces</small></li>
                    <li><small>https://www.w3.org/TR/webaudio/  Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), </small></li>
                    <li><small>https://ngrok.com/ 6 https://www.python.org/ 7 https://cycling74.com/ 8 https://www.ableton.com/en/live/max-for-liv</small></li>
                    <li><small>https://www.python.org/ 7 https://cycling74.com/ 8 https://www.ableton.com/en/live/max-for-live/ 9 ​https://p5js.org/ w</small></li>
                    <li><small>https://cycling74.com/ 8 https://www.ableton.com/en/live/max-for-live/ 9 ​https://p5js.org/ were recorded. We implement</small></li>
                    <li><small>https://www.ableton.com/en/live/max-for-live/ 9 ​https://p5js.org/ were recorded. We implemented this interface with Web        Geoloc</small></li>
                    <li><small>https://p5js.org/ were recorded. We implemented this interface with Web        Geolocation API  and MapBox </small></li>
                    <li><small>https://www.w3.org/TR/geolocation-API/ 11 https://docs.mapbox.com/api/ 12 https://librosa.github.io/librosa/ 13 https://www.kaggle.com/</small></li>
                    <li><small>https://docs.mapbox.com/api/ 12 https://librosa.github.io/librosa/ 13 https://www.kaggle.com/ 14 https://www.tensorflow.org/ </small></li>
                    <li><small>https://librosa.github.io/librosa/ 13 https://www.kaggle.com/ 14 https://www.tensorflow.org/  Proceedings of the International Con</small></li>
                    <li><small>https://www.kaggle.com/ 14 https://www.tensorflow.org/  Proceedings of the International Conference on New Interfaces fo</small></li>
                    <li><small>https://www.tensorflow.org/  Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), </small></li>
                    <li><small>https://cclab.sfc.keio.ac.jp/paper/exsampling/.  3.1  PERFORMER The performer can assign a categorized sound sample to a          prema</small></li>
                    <li><small>https://github.com/daisukelab/ml-sound-classifier  Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), </small></li>

                        </ul>
        </div>
        
                <p>
                <p>
                <a href="https://www.nime.org/proceedings/2020/nime2020_paper58.pdf" target="_blank" class="btn btn-primary my-2">Original PDF</a>             
                </p>
            </div>
            <iframe src="https://docs.google.com/forms/d/e/1FAIpQLSeeNTTMW8wbwNWr8AYITCU_78yFpR5Uyn0YRZG9iOcisxUCzw/viewform?usp=pp_url&entry.702570504=nime2020_paper58&entry.1715562253=ExSampling:+a+system+for+the+real-time+ensemble+performance+of+field-recorded+environmental+sounds" width="700" height="600" frameborder="0" marginheight="0" marginwidth="0">Loading…</iframe>
            </div>

            
            
         </section>
        

        </main>

        <footer class="text-muted py-5">
        <div class="container">
            <p class="float-end mb-1">
            <a href="#">Back to top</a>
            </p>
        </div>
        </footer>
        
        </body>
        </html>
    