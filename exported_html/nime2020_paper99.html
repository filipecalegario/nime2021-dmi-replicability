
        <!doctype html>
        <html lang="en">
        <head>
            <meta charset="utf-8">
            <meta name="viewport" content="width=device-width, initial-scale=1">
            <meta name="description" content="">
            <meta name="author" content="Filipe Calegario, Mark Otto, Jacob Thornton, and Bootstrap contributors">
            <meta name="generator" content="Hugo 0.79.0">
            <title>nime2020_paper99 - PathoSonic: Performing Sound In Virtual Reality Feature Space</title>

            <link rel="canonical" href="https://getbootstrap.com/docs/5.0/examples/album/">

            <!-- Bootstrap core CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

        </head>
        <body>
            
        <header>
        <div class="navbar navbar-dark bg-dark shadow-sm">
            <div class="container">
            <a href="#" class="navbar-brand d-flex align-items-center">
                <strong>NIME 2021 - DMI Replicability - nime2020_paper99</strong>
            </a>
            </div>
        </div>
        </header>

        <main>

        <section class="py-3 text-left container">
            <div class="row py-lg-5">
            <div class="col-lg-12 col-md-8 mx-auto">
                <h2 class="fw-light">PathoSonic: Performing Sound In Virtual Reality Feature Space</h2>
                <h5 class="fw-light text-muted">Camara Halac, Fede and Addy, Shadrick</h5>
                <h6 class="fw-light text-muted">Length: 3 pages</h6>
                <h4 class="py-2 fw-light">Abstract</h4>
                <p class="text-muted">PathoSonic is a VR experience that enables a participant to visualize and perform a sound file based on timbre feature descriptors displayed in space. The name comes from the different paths the participant can create through their sonic explorations. The goal of this research is to leverage affordances of virtual reality technology to visualize sound through different levels of performance-based interactivity that immerses the participant's body in a spatial virtual environment. Through implementation of a multi-sensory experience, including visual aesthetics, sound, and haptic feedback, we explore inclusive approaches to sound visualization, making it more accessible to a wider audience including those with hearing, and mobility impairments. The online version of the paper can be accessed here: https://fdch.github.io/pathosonic</p>
                <h4 class="fw-light">Extracted URLs from PDF</h4>
                <ul>
                    <li><a href="https://fdch.github.io/pathosonic." target="_blank">https://fdch.github.io/pathosonic.</a></li>
                    <li><a href="https://github.com/fdch/pathosonic." target="_blank">https://github.com/fdch/pathosonic.</a></li>
                    <li><a href="https://github.com/wbrent/timbreid" target="_blank">https://github.com/wbrent/timbreid</a></li>
                    <li><a href="https://github.com/libpd/libpd" target="_blank">https://github.com/libpd/libpd</a></li>
                    <li><a href="https://github.com/playdots/UnityPd" target="_blank">https://github.com/playdots/UnityPd</a></li>
                </ul>
           
                
        <div class="alert alert-warning" role="alert">
                <a class="alert-link" data-toggle="collapse" href="#debug" aria-expanded="false" aria-controls="debug">
                    Debug: if a extracted URL is malformed
                </a>
                        <ul class="font-monospace collapse" id="debug">

                            <li><small>https://fdch.github.io/pathosonic.Thecoderepositoryfortheentireprojectishere:https://github.com/fdch/pathosonic.Licensed un</small></li>
                    <li><small>https://github.com/fdch/pathosonic.Licensed under a Creative Commons Attribution4.0 International License (CC BY 4.0). Copyrightrema</small></li>
                    <li><small>https://github.com/wbrent/timbreid, 2019.[6] P. Brinkmann and the libpd team 2010-2018. libpd.https://github.com/libpd/libpd, 2019.</small></li>
                    <li><small>https://github.com/libpd/libpd, 2019.[7] R. Graham, B. Bridges, C. Manzione, and W. Brent.Exploring pitch and timbre through 3d </small></li>
                    <li><small>https://github.com/playdots/UnityPd, 2019.[11] G. Wakefield, C. Roberts, M. Wright, T. Wood, andK. Yerkes. Collaborative live-coding </small></li>

                        </ul>
        </div>
        
                <p>
                <p>
                <a href="https://www.nime.org/proceedings/2020/nime2020_paper99.pdf" target="_blank" class="btn btn-primary my-2">Original PDF</a>             
                </p>
            </div>
            <iframe src="https://docs.google.com/forms/d/e/1FAIpQLSeeNTTMW8wbwNWr8AYITCU_78yFpR5Uyn0YRZG9iOcisxUCzw/viewform?embedded=true&usp=pp_url&entry.702570504=nime2020_paper99&entry.1715562253=PathoSonic:+Performing+Sound+In+Virtual+Reality+Feature+Space" width="700" height="600" frameborder="0" marginheight="0" marginwidth="0">Loadingâ€¦</iframe>
            </div>

         </section>

        </main>

        <footer class="text-muted py-5">
        <div class="container">
            <p class="float-end mb-1">
            <a href="#">Back to top</a>
            </p>
        </div>
        </footer>
        
        </body>
        </html>
    